{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '/home/Talen/foragefish_classifier/configs/exp_resnet18.yaml'\n",
    "split = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/Talen/foragefish_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from train import create_dataloader, load_model       # NOTE: since we're using these functions across files, it could make sense to put them in e.g. a \"util.py\" script.\n",
    "\n",
    "# load config\n",
    "print(f'Using config \"{config}\"')\n",
    "cfg = yaml.safe_load(open(config, 'r'))\n",
    "\n",
    "\n",
    "# setup entities\n",
    "dl_test = create_dataloader(cfg, split='test')\n",
    "\n",
    "# load model\n",
    "model, epoch = load_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "This is up to you to figure out now. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup entities\n",
    "dl_test = create_dataloader(cfg, split='test')\n",
    "dataset = dl_test.dataset\n",
    "filenames = [entry[0] for entry in dataset.data]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device) # puts model weights on to gpu\n",
    "model.eval() # changes model to eval / inference mode\n",
    "\n",
    "\n",
    "progressBar = trange(len(dl_test))\n",
    "pred_all = []\n",
    "argmax_all = []\n",
    "img_list = []\n",
    "confs_list = []\n",
    "for idx, (data, labels) in enumerate(dl_test):       # see the last line of file \"dataset.py\" where we return the image tensor (data) and label\n",
    "\n",
    "    # put data and labels on device\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    prediction = model(data) \n",
    "    # visualize image that's stored in a batch in variable 'data' (this will be a for loop that iterates a batch)\n",
    "    # use argmax() over the prediction in a single image, apply it to every image's corresponding prediction.\n",
    "    \n",
    "    # Now we use argmax() over the prediction pair of numbers, and apply it to every image's corresponding prediction.\n",
    "    argmax = prediction.argmax(dim=1)\n",
    "\n",
    "    print(argmax)\n",
    "    \n",
    "    # print(argmax)\n",
    "    argmax_all.extend(argmax.detach().cpu().numpy())\n",
    "\n",
    "    # Using softmax to get probabilities\n",
    "    probabilities = F.softmax(prediction, dim=1)\n",
    "\n",
    "      # get the predicted labels and their confidence scores\n",
    "    pred_label = torch.argmax(probabilities, dim=1)\n",
    "    confidence_scores = torch.max(probabilities, dim=1).values\n",
    "    confidence_scores = confidence_scores.tolist()\n",
    "    print(confidence_scores)\n",
    "\n",
    "    \n",
    "\n",
    "    # store the prediction in a list\n",
    "    # pred_all.append(prediction.detach().cpu().numpy()[0])\n",
    "    pred_all.extend(prediction.detach().cpu().numpy())\n",
    "    img_list.extend(data)\n",
    "    confs_list.extend(confidence_scores)\n",
    "    \n",
    "\n",
    "\n",
    "# step 1 -visualize predictions + ground truth in matplotlib\n",
    "# Step 2 - look up weights + biases, how to set them up in the model to log during training\n",
    "# Step 3 - set up experiments so that when I start a new training run, it generates an experimental folder with the right name \n",
    "# copy config file to each experiment folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_all)\n",
    "#now we make pred_all a numpy array\n",
    "pred_all = np.array(pred_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This section of code simply creates a list of confidence scores for each image in the dataset \n",
    "by calculating the difference between the highest and second highest prediction values for each image \n",
    "(there's only two values right now, but we may have more in the future).\n",
    "\"\"\"\n",
    "\n",
    "# Now we can use the info in pred_all to calculate a confidence score for each image in the dataset:\n",
    "# now we'll write the code to do this:\n",
    "# we'll calculate the confidence score for each image in the dataset.\n",
    "# confidence score = max(prediction) - second_max(prediction)\n",
    "# we'll store this in a list called confidence_scores\n",
    "# confidence_scores = []\n",
    "# for i in range(len(pred_all)):\n",
    "#     # we'll use numpy's argsort() function to get the indices of the sorted array\n",
    "#     sorted_indices = np.argsort(pred_all[i])\n",
    "#     # we'll get the two highest values from the sorted array\n",
    "#     highest = sorted_indices[-1]\n",
    "#     second_highest = sorted_indices[-2]\n",
    "#     # we'll calculate the confidence score\n",
    "#     confidence_score = pred_all[i][1] - pred_all[i][0]  # positive for class 1, negative for class 0\n",
    "#     # we'll store the confidence score in the list\n",
    "#     confidence_scores.append(confidence_score)\n",
    "\n",
    "# # now we'll print the confidence scores\n",
    "# print(confidence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make a list of our ground-truth labels:\n",
    "gt_all = []\n",
    "for idx, (data, labels) in enumerate(dl_test):\n",
    "     gt_all.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "print(gt_all)\n",
    "\n",
    "# Now we check the type of gt_all:\n",
    "type(gt_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# Convert lists to numpy arrays for consistent handling\n",
    "# confidence_scores = np.array(confidence_scores)\n",
    "argmax_all = np.array(argmax_all)\n",
    "gt_all = np.array(gt_all)\n",
    "\n",
    "# Create DataFrame with all components\n",
    "df_combined = pd.DataFrame({\n",
    "    # 'confidence_scores': confidence_scores.tolist(),  # Convert to list for DataFrame\n",
    "    'predict_class': argmax_all,\n",
    "    'ground_truth': gt_all,\n",
    "    'image_id': range(len(img_list)),\n",
    "    'filenames':np.array(filenames),\n",
    "    'confs':confs_list\n",
    "})\n",
    "\n",
    "# Set image_id as index\n",
    "df_combined.set_index('image_id', inplace=True)\n",
    "\n",
    "# Verify structure\n",
    "print(\"DataFrame shape:\", df_combined.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create density plots with filled areas\n",
    "for gt_class in df_combined['ground_truth'].unique():\n",
    "    # Get confidence scores for this class\n",
    "    class_scores = df_combined[df_combined['ground_truth'] == gt_class]['confs']\n",
    "    \n",
    "    # Plot density with filled area\n",
    "    sns.kdeplot(data=class_scores, \n",
    "                fill=True,  # Fill area under curve\n",
    "                alpha=0.5,  # Transparency\n",
    "                label=f'Class {gt_class}')\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Confidence Scores')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Confidence Scores by Class')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create figure with two panels\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Panel 1: ground_truth = 0\n",
    "data_gt0 = df_combined[df_combined['ground_truth'] == 0]\n",
    "correct_gt0 = data_gt0[data_gt0['ground_truth'] == data_gt0['predict_class']]['confs']\n",
    "incorrect_gt0 = data_gt0[data_gt0['ground_truth'] != data_gt0['predict_class']]['confs']\n",
    "\n",
    "sns.kdeplot(data=correct_gt0, fill=True, alpha=0.5, label='Correct', ax=ax1)\n",
    "sns.kdeplot(data=incorrect_gt0, fill=True, alpha=0.5, label='Incorrect', ax=ax1)\n",
    "ax1.set_title('Ground Truth = 0 (Empty)', fontsize=16)\n",
    "ax1.set_xlabel('Confidence Scores')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Panel 2: ground_truth = 1\n",
    "data_gt1 = df_combined[df_combined['ground_truth'] == 1]\n",
    "correct_gt1 = data_gt1[data_gt1['ground_truth'] == data_gt1['predict_class']]['confs']\n",
    "incorrect_gt1 = data_gt1[data_gt1['ground_truth'] != data_gt1['predict_class']]['confs']\n",
    "\n",
    "sns.kdeplot(data=correct_gt1, fill=True, alpha=0.5, label='Correct', ax=ax2)\n",
    "sns.kdeplot(data=incorrect_gt1, fill=True, alpha=0.5, label='Incorrect', ax=ax2)\n",
    "ax2.set_title('Ground Truth = 1 (Forage Fish)', fontsize=16)\n",
    "ax2.set_xlabel('Confidence Scores')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined)\n",
    "\n",
    "\n",
    "# Now we visualize the predictions and ground truth in matplotlib\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# Let's visualize the first 10 images\n",
    "# for i in range(10):\n",
    "#     plt.imshow(data[i].permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "# Now lets visualize all images in the dataset, with their ground truth and predictions:\n",
    "# for i in range(len(df)):\n",
    "#     plt.imshow(data[i].permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# This visualizes one batch of images, but we want to visualize all images in the dataset.\n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     plt.imshow(img_list[i].cpu().permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for df_combined, we plot a batch of images listing the ground truth and confidence scores for each images using the 'filenames' column:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_batch(img_list, df_combined, start_idx=0):\n",
    "    # Create 4x3 grid with adjusted figure size\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Display up to 12 images per batch\n",
    "    for i in range(12):\n",
    "        idx = start_idx + i\n",
    "        if idx >= len(img_list):\n",
    "            break\n",
    "            \n",
    "        # Get data from dataframe\n",
    "        gt = df_combined.iloc[idx]['ground_truth']\n",
    "        pred = df_combined.iloc[idx]['predict_class']\n",
    "        conf = df_combined.iloc[idx]['confs']\n",
    "        fname = df_combined.iloc[idx]['filenames']\n",
    "            \n",
    "        # Display image and labels\n",
    "        axes[i].imshow(img_list[idx].cpu().permute(1,2,0))\n",
    "        axes[i].set_title(f'File: {fname}\\nGT: {gt}, Pred: {pred}\\nConf: {conf:.3f}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display all images in batches of 12\n",
    "for batch_start in range(0, len(df_combined), 12):\n",
    "    display_batch(img_list, df_combined, batch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing now but in a smaller grid\n",
    "\n",
    "def display_batch(img_list, gt_all, argmax_all, start_idx=0):\n",
    "    # Create 4x3 grid with adjusted figure size\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Display up to 12 images per batch\n",
    "    for i in range(12):\n",
    "        idx = start_idx + i\n",
    "        if idx >= len(img_list):\n",
    "            break\n",
    "            \n",
    "        # Display image and labels\n",
    "        axes[i].imshow(img_list[idx].cpu().permute(1,2,0))\n",
    "        axes[i].set_title(f'Image {idx}\\nGT: {gt_all[idx]}\\nPred: {argmax_all[idx]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display all images in batches of 12\n",
    "for batch_start in range(0, len(df_combined), 12):\n",
    "    display_batch(img_list, gt_all, argmax_all, batch_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ecology2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
