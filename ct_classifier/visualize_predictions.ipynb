{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '/home/Talen/foragefish_classifier/configs/exp_resnet18.yaml'\n",
    "split = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/Talen/foragefish_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from train import create_dataloader, load_model       # NOTE: since we're using these functions across files, it could make sense to put them in e.g. a \"util.py\" script.\n",
    "\n",
    "# load config\n",
    "print(f'Using config \"{config}\"')\n",
    "cfg = yaml.safe_load(open(config, 'r'))\n",
    "\n",
    "\n",
    "# setup entities\n",
    "dl_test = create_dataloader(cfg, split='test')\n",
    "\n",
    "# load model\n",
    "model, epoch = load_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "This is up to you to figure out now. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device) # puts model weights on to gpu\n",
    "model.eval() # changes model to eval / inference mode\n",
    "\n",
    "progressBar = trange(len(dl_test))\n",
    "pred_all = []\n",
    "argmax_all = []\n",
    "img_list = []\n",
    "for idx, (data, labels) in enumerate(dl_test):       # see the last line of file \"dataset.py\" where we return the image tensor (data) and label\n",
    "\n",
    "    # put data and labels on device\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    prediction = model(data) \n",
    "    # visualize image that's stored in a batch in variable 'data' (this will be a for loop that iterates a batch)\n",
    "    # use argmax() over the prediction in a single image, apply it to every image's corresponding prediction.\n",
    "    #In a list, store labels. ANd then compare the g-t classes and prediction. Create a pandas dataframe with three columns: image_name, gt, and predictions. \n",
    "    \n",
    "    # Now we use argmax() over the prediction pair of numbers, and apply it to every image's corresponding prediction.\n",
    "    argmax = prediction.argmax(dim=1)\n",
    "\n",
    "    print(argmax)\n",
    "    \n",
    "    # print(argmax)\n",
    "    argmax_all.extend(argmax.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "\n",
    "    # store the prediction in a list\n",
    "    # pred_all.append(prediction.detach().cpu().numpy()[0])\n",
    "    pred_all.extend(prediction.detach().cpu().numpy())\n",
    "    img_list.extend(data)\n",
    "    \n",
    "\n",
    "\n",
    "# step 1 -visualize predictions + ground truth in matplotlib\n",
    "# Step 2 - look up weights + biases, how to set them up in the model to log during training\n",
    "# Step 3 - set up experiments so that when I start a new training run, it generates an experimental folder with the right name \n",
    "# copy config file to each experiment folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_all)\n",
    "#now we make pred_all a numpy array\n",
    "pred_all = np.array(pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_binary_predictions(pred_all):\n",
    "    # Get max length to standardize array sizes\n",
    "    max_len = max(arr.size for arr in pred_all)\n",
    "    \n",
    "    # Initialize output array\n",
    "    transformed = []\n",
    "    \n",
    "    for pred_array in pred_all:\n",
    "        # Flatten confidence scores\n",
    "        flat_scores = pred_array.flatten()\n",
    "        \n",
    "        # Pad with zeros if needed for consistent length\n",
    "        padded = np.pad(flat_scores, \n",
    "                       (0, max_len - len(flat_scores)),\n",
    "                       'constant', \n",
    "                       constant_values=0)\n",
    "        \n",
    "        transformed.append(padded)\n",
    "    \n",
    "    return np.array(transformed)\n",
    "\n",
    "# Usage\n",
    "confidence_matrix = transform_binary_predictions(pred_all)\n",
    "print(f\"Shape: {confidence_matrix.shape}\")\n",
    "print(confidence_matrix)\n",
    "\n",
    "# now we make it a pandas dataframe:\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we combing the 'confidence_matrix' with the 'argmax_all' and 'img_list' to create a pandas dataframe:\n",
    "df = pd.DataFrame(confidence_matrix)\n",
    "df['argmax'] = argmax_all\n",
    "df['img'] = img_list\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flatten and transform data\n",
    "# img_list_flat = [img.cpu().numpy().flatten() for img in img_list]\n",
    "# pred_all_flat = [pred.flatten() for pred in pred_all]\n",
    "\n",
    "# # Create DataFrame with 1D arrays\n",
    "# df = pd.DataFrame({\n",
    "#     'image': img_list_flat,\n",
    "#     'ground truth': gt_all,\n",
    "#     'prediction': pred_all_flat\n",
    "# })\n",
    "\n",
    "# # Verify structure\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we make a histogram of the df dataframe using the seaborn library, where we plot the distribution of the confidence scores for each class., and the colour is divided based on 'gt' for each image.\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list\n",
    "\n",
    "# Now we store the img_list, argmax_all, and pred_all in a pandas dataframe:\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'image': img_list, 'argmax': argmax_all, 'prediction': })\n",
    "\n",
    "df.head()\n",
    "\n",
    "#now we make pred_all a numpy array\n",
    "pred_all = np.array(pred_all)\n",
    "\n",
    "# Now we use argmax() over the prediction pair of numbers, and apply it to every image's corresponding prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make argmax into a list (same as pred_all) and print it:\n",
    "print(argmax_all)\n",
    "len(argmax_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now we make a list of our ground-truth labels:\n",
    "gt_all = []\n",
    "for idx, (data, labels) in enumerate(dl_test):\n",
    "     gt_all.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "# print(gt_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we make a pandas dataframe with three columns: image_name, gt, and predictions.\n",
    "import pandas as pd\n",
    "# df = pd.DataFrame({'gt': gt_all, 'pred':argmax_all, 'raw_pred': pred_all})\n",
    "df = pd.DataFrame({'gt': gt_all, 'pred':argmax_all})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we visualize the predictions and ground truth in matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Let's visualize the first 10 images\n",
    "# for i in range(10):\n",
    "#     plt.imshow(data[i].permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "# Now lets visualize all images in the dataset, with their ground truth and predictions:\n",
    "# for i in range(len(df)):\n",
    "#     plt.imshow(data[i].permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# This visualizes one batch of images, but we want to visualize all images in the dataset.\n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     plt.imshow(img_list[i].cpu().permute(1,2,0))\n",
    "#     plt.title(f'Ground truth: {gt_all[i]}, Prediction: {argmax_all[i]}')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing now but in a smaller grid\n",
    "\n",
    "def display_batch(img_list, gt_all, argmax_all, start_idx=0):\n",
    "    # Create 4x3 grid with adjusted figure size\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Display up to 12 images per batch\n",
    "    for i in range(12):\n",
    "        idx = start_idx + i\n",
    "        if idx >= len(img_list):\n",
    "            break\n",
    "            \n",
    "        # Display image and labels\n",
    "        axes[i].imshow(img_list[idx].cpu().permute(1,2,0))\n",
    "        axes[i].set_title(f'Image {idx}\\nGT: {gt_all[idx]}\\nPred: {argmax_all[idx]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display all images in batches of 12\n",
    "for batch_start in range(0, len(df), 12):\n",
    "    display_batch(img_list, gt_all, argmax_all, batch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: visualize and evaluate\n",
    "# Visualize - look @ images and compare to prediction we got.\n",
    "\n",
    "# Now we want to plot a histogram visualizing the distribution of the confidence in each image by our model, seperated by empty and forage fish images:\n",
    "import seaborn as sns\n",
    "sns.histplot(df['gt'], color='blue', alpha=0.5, label='Ground Truth')\n",
    "sns.histplot(df['pred'], color='red', alpha=0.5, label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# These should have different colours with an alpha value to see the overlap.\n",
    "# We will use the matplotlib library to plot this.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Now we want to visualize the predictions and ground truth in matplotlib in a plot:\n",
    "# plt.plot(df['gt'], label='Ground Truth')\n",
    "# plt.plot(df['pred'], label='Prediction')\n",
    "# #give the x-axis a label\n",
    "# plt.xlabel('Image')\n",
    "# #give the y-axis a label\n",
    "# plt.ylabel('Class')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# import sklearn\n",
    "# print(sklearn.__version__)\n",
    "\n",
    "\n",
    "# # Now print the accuracy of the model:\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy = accuracy_score(df['gt'], df['pred'])\n",
    "# print(f'Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ecology2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
